{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pdfs from arxiv.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set up to use local modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..')) # Add parent directory to path\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprojroot\n",
    "\n",
    "from src import utils\n",
    "\n",
    "PDF_DIR = pyprojroot.here(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation of an inverse turbulent-wave cascade in a driven quantum gas\n",
      "Robustness of Fixed Points of Quantum Channels and Application to Approximate Quantum Markov Chains\n",
      "Polarization dependent non-Hermitian atomic grating controlled by dipole blockade effect\n",
      "Centerless-BMS charge algebra\n",
      "Driven Multiphoton Qubit-Resonator Interactions\n",
      "Geometric Quantization Without Polarizations\n",
      "Effective Lifshitz black holes, hydrodynamics, and transport coefficients in fluid/gravity correspondence\n",
      "Optical Manipulation of Spin States in Ultracold Magnetic Atoms via an Inner-Shell Hz Transition\n",
      "Single-layer tensor network approach for three-dimensional quantum systems\n",
      "A Formulation of Quantum Fluid Mechanics and Trajectories\n"
     ]
    }
   ],
   "source": [
    "# https://lukasschwab.me/arxiv.py/arxiv.html\n",
    "\n",
    "import arxiv\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "search = arxiv.Search(\n",
    "    query=\"quantum\", max_results=10, sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "# `results` is a generator; you can iterate over its elements one by one...\n",
    "for r in client.results(search):\n",
    "    print(r.title)\n",
    "# ...or exhaust it into a list. Careful: this is slow for large results sets.\n",
    "# all_results = list(results)\n",
    "# print([r.title for r in all_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jordan/documents/GitHub/arxiv-chat/data/example_paper.pdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_ids = [\"1706.03762v6\", \"1605.08386v1\"]\n",
    "\n",
    "# Search for the paper with ID \"1605.08386v1\"\n",
    "search_by_id = arxiv.Search(id_list=[pdf_ids[0]])\n",
    "paper = next(client.results(search_by_id))\n",
    "print(paper.title)\n",
    "\n",
    "paper.download_pdf(dirpath=PDF_DIR, filename=\"example_paper.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded: Attention is All You Need\n",
      "Already downloaded: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "Already downloaded: Generative Adversarial Nets\n",
      "Already downloaded: Playing Atari with Deep Reinforcement Learning\n",
      "Already downloaded: ImageNet Classification with Deep Convolutional Neural Networks\n"
     ]
    }
   ],
   "source": [
    "papers = utils.local_papers\n",
    "\n",
    "utils.get_local_papers(papers=papers, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most recent ML papers from arxiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Space Alignments Towards Universal LiDAR Segmentation\n",
      "A unified and versatile LiDAR segmentation model with strong robustness and\n",
      "generalizability is desirable for safe autonomous driving perception. This work\n",
      "presents M3Net, a one-of-a-kind framework for fulfilling multi-task,\n",
      "multi-dataset, multi-modality LiDAR segmentation in a universal manner using\n",
      "just a single set of parameters. To better exploit data volume and diversity,\n",
      "we first combine large-scale driving datasets acquired by different types of\n",
      "sensors from diverse scenes and then conduct alignments in three spaces, namely\n",
      "data, feature, and label spaces, during the training. As a result, M3Net is\n",
      "capable of taming heterogeneous data for training state-of-the-art LiDAR\n",
      "segmentation models. Extensive experiments on twelve LiDAR segmentation\n",
      "datasets verify our effectiveness. Notably, using a shared set of parameters,\n",
      "M3Net achieves 75.1%, 83.1%, and 72.4% mIoU scores, respectively, on the\n",
      "official benchmarks of SemanticKITTI, nuScenes, and Waymo Open.\n",
      "Customizing Text-to-Image Models with a Single Image Pair\n",
      "Art reinterpretation is the practice of creating a variation of a reference\n",
      "work, making a paired artwork that exhibits a distinct artistic style. We ask\n",
      "if such an image pair can be used to customize a generative model to capture\n",
      "the demonstrated stylistic difference. We propose Pair Customization, a new\n",
      "customization method that learns stylistic difference from a single image pair\n",
      "and then applies the acquired style to the generation process. Unlike existing\n",
      "methods that learn to mimic a single concept from a collection of images, our\n",
      "method captures the stylistic difference between paired images. This allows us\n",
      "to apply a stylistic change without overfitting to the specific image content\n",
      "in the examples. To address this new task, we employ a joint optimization\n",
      "method that explicitly separates the style and content into distinct LoRA\n",
      "weight spaces. We optimize these style and content weights to reproduce the\n",
      "style and content images while encouraging their orthogonality. During\n",
      "inference, we modify the diffusion process via a new style guidance based on\n",
      "our learned weights. Both qualitative and quantitative experiments show that\n",
      "our method can effectively learn style while avoiding overfitting to image\n",
      "content, highlighting the potential of modeling such stylistic differences from\n",
      "a single image pair.\n",
      "Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks\n",
      "Large Language Models (LLMs) have been shown to be capable of performing\n",
      "high-level planning for long-horizon robotics tasks, yet existing methods\n",
      "require access to a pre-defined skill library (e.g. picking, placing, pulling,\n",
      "pushing, navigating). However, LLM planning does not address how to design or\n",
      "learn those behaviors, which remains challenging particularly in long-horizon\n",
      "settings. Furthermore, for many tasks of interest, the robot needs to be able\n",
      "to adjust its behavior in a fine-grained manner, requiring the agent to be\n",
      "capable of modifying low-level control actions. Can we instead use the\n",
      "internet-scale knowledge from LLMs for high-level policies, guiding\n",
      "reinforcement learning (RL) policies to efficiently solve robotic control tasks\n",
      "online without requiring a pre-determined set of skills? In this paper, we\n",
      "propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to\n",
      "bridge the gap between abstract language and learned low-level control for\n",
      "solving long-horizon robotics tasks from scratch. We demonstrate that PSL\n",
      "achieves state-of-the-art results on over 25 challenging robotics tasks with up\n",
      "to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four\n",
      "benchmarks at success rates of over 85%, out-performing language-based,\n",
      "classical, and end-to-end approaches. Video results and code at\n",
      "https://mihdalal.github.io/planseqlearn/\n",
      "Improving Intervention Efficacy via Concept Realignment in Concept Bottleneck Models\n",
      "Concept Bottleneck Models (CBMs) ground image classification on\n",
      "human-understandable concepts to allow for interpretable model decisions.\n",
      "Crucially, the CBM design inherently allows for human interventions, in which\n",
      "expert users are given the ability to modify potentially misaligned concept\n",
      "choices to influence the decision behavior of the model in an interpretable\n",
      "fashion. However, existing approaches often require numerous human\n",
      "interventions per image to achieve strong performances, posing practical\n",
      "challenges in scenarios where obtaining human feedback is expensive. In this\n",
      "paper, we find that this is noticeably driven by an independent treatment of\n",
      "concepts during intervention, wherein a change of one concept does not\n",
      "influence the use of other ones in the model's final decision. To address this\n",
      "issue, we introduce a trainable concept intervention realignment module, which\n",
      "leverages concept relations to realign concept assignments post-intervention.\n",
      "Across standard, real-world benchmarks, we find that concept realignment can\n",
      "significantly improve intervention efficacy; significantly reducing the number\n",
      "of interventions needed to reach a target classification performance or concept\n",
      "prediction accuracy. In addition, it easily integrates into existing\n",
      "concept-based architectures without requiring changes to the models themselves.\n",
      "This reduced cost of human-model collaboration is crucial to enhancing the\n",
      "feasibility of CBMs in resource-constrained environments.\n",
      "A separability-based approach to quantifying generalization: which layer is best?\n",
      "Generalization to unseen data remains poorly understood for deep learning\n",
      "classification and foundation models. How can one assess the ability of\n",
      "networks to adapt to new or extended versions of their input space in the\n",
      "spirit of few-shot learning, out-of-distribution generalization, and domain\n",
      "adaptation? Which layers of a network are likely to generalize best? We provide\n",
      "a new method for evaluating the capacity of networks to represent a sampled\n",
      "domain, regardless of whether the network has been trained on all classes in\n",
      "the domain. Our approach is the following: after fine-tuning state-of-the-art\n",
      "pre-trained models for visual classification on a particular domain, we assess\n",
      "their performance on data from related but distinct variations in that domain.\n",
      "Generalization power is quantified as a function of the latent embeddings of\n",
      "unseen data from intermediate layers for both unsupervised and supervised\n",
      "settings. Working throughout all stages of the network, we find that (i) high\n",
      "classification accuracy does not imply high generalizability; and (ii) deeper\n",
      "layers in a model do not always generalize the best, which has implications for\n",
      "pruning. Since the trends observed across datasets are largely consistent, we\n",
      "conclude that our approach reveals (a function of) the intrinsic capacity of\n",
      "the different layers of a model to generalize.\n",
      "Transformer-Aided Semantic Communications\n",
      "The transformer structure employed in large language models (LLMs), as a\n",
      "specialized category of deep neural networks (DNNs) featuring attention\n",
      "mechanisms, stands out for their ability to identify and highlight the most\n",
      "relevant aspects of input data. Such a capability is particularly beneficial in\n",
      "addressing a variety of communication challenges, notably in the realm of\n",
      "semantic communication where proper encoding of the relevant data is critical\n",
      "especially in systems with limited bandwidth. In this work, we employ vision\n",
      "transformers specifically for the purpose of compression and compact\n",
      "representation of the input image, with the goal of preserving semantic\n",
      "information throughout the transmission process. Through the use of the\n",
      "attention mechanism inherent in transformers, we create an attention mask. This\n",
      "mask effectively prioritizes critical segments of images for transmission,\n",
      "ensuring that the reconstruction phase focuses on key objects highlighted by\n",
      "the mask. Our methodology significantly improves the quality of semantic\n",
      "communication and optimizes bandwidth usage by encoding different parts of the\n",
      "data in accordance with their semantic information content, thus enhancing\n",
      "overall efficiency. We evaluate the effectiveness of our proposed framework\n",
      "using the TinyImageNet dataset, focusing on both reconstruction quality and\n",
      "accuracy. Our evaluation results demonstrate that our framework successfully\n",
      "preserves semantic information, even when only a fraction of the encoded data\n",
      "is transmitted, according to the intended compression rates.\n",
      "Accelerating Convergence in Bayesian Few-Shot Classification\n",
      "Bayesian few-shot classification has been a focal point in the field of\n",
      "few-shot learning. This paper seamlessly integrates mirror descent-based\n",
      "variational inference into Gaussian process-based few-shot classification,\n",
      "addressing the challenge of non-conjugate inference. By leveraging\n",
      "non-Euclidean geometry, mirror descent achieves accelerated convergence by\n",
      "providing the steepest descent direction along the corresponding manifold. It\n",
      "also exhibits the parameterization invariance property concerning the\n",
      "variational distribution. Experimental results demonstrate competitive\n",
      "classification accuracy, improved uncertainty quantification, and faster\n",
      "convergence compared to baseline models. Additionally, we investigate the\n",
      "impact of hyperparameters and components. Code is publicly available at\n",
      "https://github.com/keanson/MD-BSFC.\n",
      "Analyzing the Role of Semantic Representations in the Era of Large Language Models\n",
      "Traditionally, natural language processing (NLP) models often use a rich set\n",
      "of features created by linguistic expertise, such as semantic representations.\n",
      "However, in the era of large language models (LLMs), more and more tasks are\n",
      "turned into generic, end-to-end sequence generation problems. In this paper, we\n",
      "investigate the question: what is the role of semantic representations in the\n",
      "era of LLMs? Specifically, we investigate the effect of Abstract Meaning\n",
      "Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven\n",
      "chain-of-thought prompting method, which we call AMRCoT, and find that it\n",
      "generally hurts performance more than it helps. To investigate what AMR may\n",
      "have to offer on these tasks, we conduct a series of analysis experiments. We\n",
      "find that it is difficult to predict which input examples AMR may help or hurt\n",
      "on, but errors tend to arise with multi-word expressions, named entities, and\n",
      "in the final inference step where the LLM must connect its reasoning over the\n",
      "AMR to its prediction. We recommend focusing on these areas for future work in\n",
      "semantic representations for LLMs. Our code:\n",
      "https://github.com/causalNLP/amr_llm.\n",
      "Navigating Heterogeneity and Privacy in One-Shot Federated Learning with Diffusion Models\n",
      "Federated learning (FL) enables multiple clients to train models collectively\n",
      "while preserving data privacy. However, FL faces challenges in terms of\n",
      "communication cost and data heterogeneity. One-shot federated learning has\n",
      "emerged as a solution by reducing communication rounds, improving efficiency,\n",
      "and providing better security against eavesdropping attacks. Nevertheless, data\n",
      "heterogeneity remains a significant challenge, impacting performance. This work\n",
      "explores the effectiveness of diffusion models in one-shot FL, demonstrating\n",
      "their applicability in addressing data heterogeneity and improving FL\n",
      "performance. Additionally, we investigate the utility of our diffusion model\n",
      "approach, FedDiff, compared to other one-shot FL methods under differential\n",
      "privacy (DP). Furthermore, to improve generated sample quality under DP\n",
      "settings, we propose a pragmatic Fourier Magnitude Filtering (FMF) method,\n",
      "enhancing the effectiveness of generated data for global model training.\n",
      "FeNNol: an Efficient and Flexible Library for Building Force-field-enhanced Neural Network Potentials\n",
      "Neural network interatomic potentials (NNPs) have recently proven to be\n",
      "powerful tools to accurately model complex molecular systems while bypassing\n",
      "the high numerical cost of ab-initio molecular dynamics simulations. In recent\n",
      "years, numerous advances in model architectures as well as the development of\n",
      "hybrid models combining machine-learning (ML) with more traditional,\n",
      "physically-motivated, force-field interactions have considerably increased the\n",
      "design space of ML potentials. In this paper, we present FeNNol, a new library\n",
      "for building, training and running force-field-enhanced neural network\n",
      "potentials. It provides a flexible and modular system for building hybrid\n",
      "models, allowing to easily combine state-of-the-art embeddings with\n",
      "ML-parameterized physical interaction terms without the need for explicit\n",
      "programming. Furthermore, FeNNol leverages the automatic differentiation and\n",
      "just-in-time compilation features of the Jax Python library to enable fast\n",
      "evaluation of NNPs, shrinking the performance gap between ML potentials and\n",
      "standard force-fields. This is demonstrated with the popular ANI-2x model\n",
      "reaching simulation speeds nearly on par with the AMOEBA polarizable\n",
      "force-field on commodity GPUs (GPU=Graphics processing unit). We hope that\n",
      "FeNNol will facilitate the development and application of new hybrid NNP\n",
      "architectures for a wide range of molecular simulation problems.\n"
     ]
    }
   ],
   "source": [
    "# Use the `arxiv` package to get the 10 most recent papers on the topic of cs.LG\n",
    "# Papers categorized with stat.ML as primary are automatically cross-listed as cs.LG but not vice versa.\n",
    "# Computer science: Machine Learning = cs.LG\n",
    "# Other,\n",
    "# Statistics: Machine Learning = stat.ML\n",
    "# Computer science: Artificial Intelligence = cs.AI\n",
    "# Computer science: Neural and Evolutionary Computing = cs.NE\n",
    "# Computer science: Systems and Control = cs.SY\n",
    "# Math: Optimization and Control = math.OC\n",
    "\n",
    "search = arxiv.Search(\n",
    "    query=\"cs.LG\", max_results=10, sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "# Print the titles\n",
    "for r in results:\n",
    "    print(r.title)\n",
    "    print(r.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first paper from results\n",
    "paper = next(client.results(search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Result(entry_id='http://arxiv.org/abs/2405.01538v1', updated=datetime.datetime(2024, 5, 2, 17, 59, 57, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 2, 17, 59, 57, tzinfo=datetime.timezone.utc), title='Multi-Space Alignments Towards Universal LiDAR Segmentation', authors=[arxiv.Result.Author('Youquan Liu'), arxiv.Result.Author('Lingdong Kong'), arxiv.Result.Author('Xiaoyang Wu'), arxiv.Result.Author('Runnan Chen'), arxiv.Result.Author('Xin Li'), arxiv.Result.Author('Liang Pan'), arxiv.Result.Author('Ziwei Liu'), arxiv.Result.Author('Yuexin Ma')], summary='A unified and versatile LiDAR segmentation model with strong robustness and\\ngeneralizability is desirable for safe autonomous driving perception. This work\\npresents M3Net, a one-of-a-kind framework for fulfilling multi-task,\\nmulti-dataset, multi-modality LiDAR segmentation in a universal manner using\\njust a single set of parameters. To better exploit data volume and diversity,\\nwe first combine large-scale driving datasets acquired by different types of\\nsensors from diverse scenes and then conduct alignments in three spaces, namely\\ndata, feature, and label spaces, during the training. As a result, M3Net is\\ncapable of taming heterogeneous data for training state-of-the-art LiDAR\\nsegmentation models. Extensive experiments on twelve LiDAR segmentation\\ndatasets verify our effectiveness. Notably, using a shared set of parameters,\\nM3Net achieves 75.1%, 83.1%, and 72.4% mIoU scores, respectively, on the\\nofficial benchmarks of SemanticKITTI, nuScenes, and Waymo Open.', comment='CVPR 2024; 33 pages, 14 figures, 14 tables; Code at\\n  https://github.com/youquanl/M3Net', journal_ref=None, doi=None, primary_category='cs.CV', categories=['cs.CV', 'cs.LG', 'cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.01538v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.01538v1', title='pdf', rel='related', content_type=None)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all ML papers from today\n",
    "\n",
    "# https://export.arxiv.org/api/query?search_query=cat:cs.LG+AND+submittedDate:[202001130630+TO+202001131645]\n",
    "\n",
    "query = \"cs.LG\"\n",
    "# query by submitteDate is not implemented in the Python API\n",
    "# query = \"cat:cs.LG+AND+submittedDate:[202001130630+TO+202101131645]\"\n",
    "search = arxiv.Search(\n",
    "    query=query, max_results=10, sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "# Print the titles\n",
    "for r in results:\n",
    "    print(r.title)\n",
    "    print(r.published)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
